{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5c2RlHXmV7N2"
      },
      "source": [
        "# Wav2Lip: lip-sync videos\n",
        "\n",
        "## [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ml4a/ml4a-guides/blob/ml4a.net/examples/models/BASnet.ipynb)\n",
        "\n",
        "Given an image or video containing a face and audio containing speech, outputs a video in which the face is animated lip-syncing the speech. See the [original code](https://github.com/Rudrabha/Wav2Lip) and [paper](https://arxiv.org/abs/2008.10010)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KYS22Xj7V7N5"
      },
      "source": [
        "## Set up ml4a and enable GPU\n",
        "\n",
        "If you don't already have ml4a installed, or you are opening this in Colab, first enable GPU (`Runtime` > `Change runtime type`), then run the following cell to install ml4a and its dependencies."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "-NHwVgMRV7N6",
        "outputId": "f2e06888-65c8-407d-9287-e3a3f4cb5239",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 371
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Tensorflow 1 is unsupported in Colab.\n\nYour notebook should be updated to use Tensorflow 2.\nSee the guide at https://www.tensorflow.org/guide/migrate#migrate-from-tensorflow-1x-to-tensorflow-2.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2054640651.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'tensorflow_version'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'1.x'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pip3 install --quiet ml4a'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_line_magic\u001b[0;34m(self, magic_name, line, _stack_depth)\u001b[0m\n\u001b[1;32m   2416\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'local_ns'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_local_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2417\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2418\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2419\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2420\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_tensorflow_magics.py\u001b[0m in \u001b[0;36m_tensorflow_version\u001b[0;34m(line)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     raise ValueError(\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0;31m# pylint: disable=line-too-long\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         textwrap.dedent(\n",
            "\u001b[0;31mValueError\u001b[0m: Tensorflow 1 is unsupported in Colab.\n\nYour notebook should be updated to use Tensorflow 2.\nSee the guide at https://www.tensorflow.org/guide/migrate#migrate-from-tensorflow-1x-to-tensorflow-2."
          ]
        }
      ],
      "source": [
        "%tensorflow_version 1.x\n",
        "!pip3 install --quiet ml4a"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CAUY5GwaV7N8"
      },
      "source": [
        "# Example Wav2Lip\n",
        "\n",
        "We can load a sample clip from `ml4a.audio` and plot the waveform."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nAdEVjUbV7N9"
      },
      "outputs": [],
      "source": [
        "from ml4a import audio\n",
        "\n",
        "input_audio, sample_rate = audio.sample_audio()\n",
        "\n",
        "%matplotlib inline\n",
        "audio.plot(input_audio, sample_rate)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gV4cUhYqV7N_"
      },
      "source": [
        "And to listen to it:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MtBXz17UV7OA"
      },
      "outputs": [],
      "source": [
        "audio.display(input_audio, sample_rate)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZkNGqPAlV7OC"
      },
      "source": [
        "We'll load a sample image and run it through `ml4a.models.wav2lip`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w0q0qnzLV7OD"
      },
      "outputs": [],
      "source": [
        "from ml4a import audio\n",
        "from ml4a import image\n",
        "from ml4a.models import wav2lip\n",
        "\n",
        "input_image = image.monalisa()\n",
        "\n",
        "input_audio, sample_rate = audio.sample_audio()\n",
        "\n",
        "wav2lip.run(input_image,\n",
        "            input_audio,\n",
        "            sampling_rate = sample_rate,\n",
        "            output_video = 'wav2lip_example.mp4',\n",
        "            pads = [0, 10, 0, 0],\n",
        "            resize_factor = 2,\n",
        "            crop = None,\n",
        "            box = None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3tPWzmLGV7OE"
      },
      "source": [
        "Display the generated video."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Ce7K7ElV7OF"
      },
      "outputs": [],
      "source": [
        "image.display_local('wav2lip_example.mp4')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}